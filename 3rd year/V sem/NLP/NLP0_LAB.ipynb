{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfe4533a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\naman\\anaconda3\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\naman\\anaconda3\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: regex in c:\\users\\naman\\anaconda3\\lib\\site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: click in c:\\users\\naman\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\naman\\anaconda3\\lib\\site-packages (from nltk) (4.59.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "298c92bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk as n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929524d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b5f0761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c921affa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c49b2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abc', 'abc.zip', 'alpino', 'alpino.zip', 'biocreative_ppi', 'biocreative_ppi.zip', 'brown', 'brown.zip', 'brown_tei', 'brown_tei.zip', 'cess_cat', 'cess_cat.zip', 'cess_esp', 'cess_esp.zip', 'chat80', 'chat80.zip', 'city_database', 'city_database.zip', 'cmudict', 'cmudict.zip', 'comparative_sentences', 'comparative_sentences.zip', 'comtrans.zip', 'conll2000', 'conll2000.zip', 'conll2002', 'conll2002.zip', 'conll2007.zip', 'crubadan', 'crubadan.zip', 'dependency_treebank', 'dependency_treebank.zip', 'dolch', 'dolch.zip', 'europarl_raw', 'europarl_raw.zip', 'extended_omw.zip', 'floresta', 'floresta.zip', 'framenet_v15', 'framenet_v15.zip', 'framenet_v17', 'framenet_v17.zip', 'gazetteers', 'gazetteers.zip', 'genesis', 'genesis.zip', 'gutenberg', 'gutenberg.zip', 'ieer', 'ieer.zip', 'inaugural', 'inaugural.zip', 'indian', 'indian.zip', 'jeita.zip', 'kimmo', 'kimmo.zip', 'knbc.zip', 'lin_thesaurus', 'lin_thesaurus.zip', 'machado.zip', 'mac_morpho', 'mac_morpho.zip', 'masc_tagged.zip', 'movie_reviews', 'movie_reviews.zip', 'mte_teip5', 'mte_teip5.zip', 'names', 'names.zip', 'nombank.1.0.zip', 'nonbreaking_prefixes', 'nonbreaking_prefixes.zip', 'nps_chat', 'nps_chat.zip', 'omw-1.4.zip', 'omw.zip', 'opinion_lexicon', 'opinion_lexicon.zip', 'panlex_swadesh.zip', 'paradigms', 'paradigms.zip', 'pe08', 'pe08.zip', 'pil', 'pil.zip', 'pl196x', 'pl196x.zip', 'ppattach', 'ppattach.zip', 'problem_reports', 'problem_reports.zip', 'product_reviews_1', 'product_reviews_1.zip', 'product_reviews_2', 'product_reviews_2.zip', 'propbank.zip', 'pros_cons', 'pros_cons.zip', 'ptb', 'ptb.zip', 'qc', 'qc.zip', 'reuters.zip', 'rte', 'rte.zip', 'semcor.zip', 'senseval', 'senseval.zip', 'sentence_polarity', 'sentence_polarity.zip', 'sentiwordnet', 'sentiwordnet.zip', 'shakespeare', 'shakespeare.zip', 'sinica_treebank', 'sinica_treebank.zip', 'smultron', 'smultron.zip', 'state_union', 'state_union.zip', 'stopwords', 'stopwords.zip', 'subjectivity', 'subjectivity.zip', 'swadesh', 'swadesh.zip', 'switchboard', 'switchboard.zip', 'timit', 'timit.zip', 'toolbox', 'toolbox.zip', 'treebank', 'treebank.zip', 'twitter_samples', 'twitter_samples.zip', 'udhr', 'udhr.zip', 'udhr2', 'udhr2.zip', 'unicode_samples', 'unicode_samples.zip', 'universal_treebanks_v20.zip', 'verbnet', 'verbnet.zip', 'verbnet3', 'verbnet3.zip', 'webtext', 'webtext.zip', 'wordnet.zip', 'wordnet2021.zip', 'wordnet31.zip', 'wordnet_ic', 'wordnet_ic.zip', 'words', 'words.zip', 'ycoe', 'ycoe.zip']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(nltk.data.find('corpora'))) #display all the files present in nltk library they are text files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bda8bbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown  #to import to be able to read it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84702faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]\n"
     ]
    }
   ],
   "source": [
    "print(brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a882ec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a14ec3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "Fulton\n",
      "County\n",
      "Grand\n",
      "Jury\n",
      "said\n",
      "Friday\n",
      "an\n",
      "investigation\n",
      "of\n",
      "Atlanta's\n",
      "recent\n",
      "primary\n",
      "election\n",
      "produced\n",
      "``\n",
      "no\n",
      "evidence\n",
      "''\n",
      "that\n",
      "any\n",
      "irregularities\n",
      "took\n",
      "place\n",
      ".\n",
      "The\n",
      "jury\n",
      "further\n",
      "said\n",
      "in\n",
      "term-end\n",
      "presentments\n",
      "that\n",
      "the\n",
      "City\n",
      "Executive\n",
      "Committee\n",
      ",\n",
      "which\n",
      "had\n",
      "over-all\n",
      "charge\n",
      "of\n",
      "the\n",
      "election\n",
      ",\n",
      "``\n",
      "deserves\n",
      "the\n",
      "praise\n",
      "and\n",
      "thanks\n",
      "of\n",
      "the\n",
      "City\n",
      "of\n",
      "Atlanta\n",
      "''\n",
      "for\n",
      "the\n",
      "manner\n",
      "in\n",
      "which\n",
      "the\n",
      "election\n",
      "was\n",
      "conducted\n",
      ".\n",
      "The\n",
      "September-October\n",
      "term\n",
      "jury\n",
      "had\n",
      "been\n",
      "charged\n",
      "by\n",
      "Fulton\n",
      "Superior\n",
      "Court\n",
      "Judge\n",
      "Durwood\n",
      "Pye\n",
      "to\n",
      "investigate\n",
      "reports\n",
      "of\n",
      "possible\n",
      "``\n",
      "irregularities\n",
      "''\n",
      "in\n",
      "the\n",
      "hard-fought\n",
      "primary\n",
      "which\n",
      "was\n",
      "won\n",
      "by\n",
      "Mayor-nominate\n",
      "Ivan\n",
      "Allen\n",
      "Jr.\n",
      ".\n",
      "``\n",
      "Only\n",
      "a\n",
      "relative\n",
      "handful\n",
      "of\n",
      "such\n",
      "reports\n",
      "was\n",
      "received\n",
      "''\n",
      ",\n",
      "the\n",
      "jury\n",
      "said\n",
      ",\n",
      "``\n",
      "considering\n",
      "the\n",
      "widespread\n",
      "interest\n",
      "in\n",
      "the\n",
      "election\n",
      ",\n",
      "the\n",
      "number\n",
      "of\n",
      "voters\n",
      "and\n",
      "the\n",
      "size\n",
      "of\n",
      "this\n",
      "city\n",
      "''\n",
      ".\n",
      "The\n",
      "jury\n",
      "said\n",
      "it\n",
      "did\n",
      "find\n",
      "that\n",
      "many\n",
      "of\n",
      "Georgia's\n",
      "registration\n",
      "and\n",
      "election\n",
      "laws\n",
      "``\n",
      "are\n",
      "outmoded\n",
      "or\n",
      "inadequate\n",
      "and\n",
      "often\n",
      "ambiguous\n",
      "''\n",
      ".\n",
      "It\n",
      "recommended\n",
      "that\n",
      "Fulton\n",
      "legislators\n",
      "act\n",
      "``\n",
      "to\n",
      "have\n",
      "these\n",
      "laws\n",
      "studied\n",
      "and\n",
      "revised\n",
      "to\n",
      "the\n",
      "end\n",
      "of\n",
      "modernizing\n",
      "and\n",
      "improving\n",
      "them\n",
      "''\n",
      ".\n",
      "The\n",
      "grand\n",
      "jury\n",
      "commented\n",
      "on\n",
      "a\n",
      "number\n",
      "of\n",
      "other\n",
      "topics\n",
      ",\n",
      "among\n",
      "them\n",
      "the\n",
      "Atlanta\n",
      "and\n",
      "Fulton\n",
      "County\n",
      "purchasing\n",
      "departments\n",
      "which\n",
      "it\n",
      "said\n",
      "``\n",
      "are\n",
      "well\n",
      "operated\n",
      "and\n",
      "follow\n",
      "generally\n",
      "accepted\n",
      "practices\n",
      "which\n",
      "inure\n",
      "to\n",
      "the\n",
      "best\n",
      "interest\n",
      "of\n",
      "both\n",
      "governments\n",
      "''\n",
      ".\n",
      "Merger\n",
      "proposed\n",
      "However\n",
      ",\n",
      "the\n",
      "jury\n",
      "said\n",
      "it\n",
      "believes\n",
      "``\n",
      "these\n",
      "two\n",
      "offices\n",
      "should\n",
      "be\n",
      "combined\n",
      "to\n",
      "achieve\n",
      "greater\n",
      "efficiency\n",
      "and\n",
      "reduce\n",
      "the\n",
      "cost\n",
      "of\n",
      "administration\n",
      "''\n",
      ".\n",
      "The\n",
      "City\n",
      "Purchasing\n",
      "Department\n",
      ",\n",
      "the\n",
      "jury\n",
      "said\n",
      ",\n",
      "``\n",
      "is\n",
      "lacking\n",
      "in\n",
      "experienced\n",
      "clerical\n",
      "personnel\n",
      "as\n",
      "a\n",
      "result\n",
      "of\n",
      "city\n",
      "personnel\n",
      "policies\n",
      "''\n",
      ".\n",
      "It\n",
      "urged\n",
      "that\n",
      "the\n",
      "city\n",
      "``\n",
      "take\n",
      "steps\n",
      "to\n",
      "remedy\n",
      "''\n",
      "this\n",
      "problem\n",
      ".\n",
      "Implementation\n",
      "of\n",
      "Georgia's\n",
      "automobile\n",
      "title\n",
      "law\n",
      "was\n",
      "also\n",
      "recommended\n",
      "by\n",
      "the\n",
      "outgoing\n",
      "jury\n",
      ".\n",
      "It\n",
      "urged\n",
      "that\n",
      "the\n",
      "next\n",
      "Legislature\n",
      "``\n",
      "provide\n",
      "enabling\n",
      "funds\n",
      "and\n",
      "re-set\n",
      "the\n",
      "effective\n",
      "date\n",
      "so\n",
      "that\n",
      "an\n",
      "orderly\n",
      "implementation\n",
      "of\n",
      "the\n",
      "law\n",
      "may\n",
      "be\n",
      "effected\n",
      "''\n",
      ".\n",
      "The\n",
      "grand\n",
      "jury\n",
      "took\n",
      "a\n",
      "swipe\n",
      "at\n",
      "the\n",
      "State\n",
      "Welfare\n",
      "Department's\n",
      "handling\n",
      "of\n",
      "federal\n",
      "funds\n",
      "granted\n",
      "for\n",
      "child\n",
      "welfare\n",
      "services\n",
      "in\n",
      "foster\n",
      "homes\n",
      ".\n",
      "``\n",
      "This\n",
      "is\n",
      "one\n",
      "of\n",
      "the\n",
      "major\n",
      "items\n",
      "in\n",
      "the\n",
      "Fulton\n",
      "County\n",
      "general\n",
      "assistance\n",
      "program\n",
      "''\n",
      ",\n",
      "the\n",
      "jury\n",
      "said\n",
      ",\n",
      "but\n",
      "the\n",
      "State\n",
      "Welfare\n",
      "Department\n",
      "``\n",
      "has\n",
      "seen\n",
      "fit\n",
      "to\n",
      "distribute\n",
      "these\n",
      "funds\n",
      "through\n",
      "the\n",
      "welfare\n",
      "departments\n",
      "of\n",
      "all\n",
      "the\n",
      "counties\n",
      "in\n",
      "the\n",
      "state\n",
      "with\n",
      "the\n",
      "exception\n",
      "of\n",
      "Fulton\n",
      "County\n",
      ",\n",
      "which\n",
      "receives\n",
      "none\n",
      "of\n",
      "this\n",
      "money\n",
      ".\n",
      "The\n",
      "jurors\n",
      "said\n",
      "they\n",
      "realize\n",
      "``\n",
      "a\n",
      "proportionate\n",
      "distribution\n",
      "of\n",
      "these\n",
      "funds\n",
      "might\n",
      "disable\n",
      "this\n",
      "program\n",
      "in\n",
      "our\n",
      "less\n",
      "populous\n",
      "counties\n",
      "''\n",
      ".\n",
      "Nevertheless\n",
      ",\n",
      "``\n",
      "we\n",
      "feel\n",
      "that\n",
      "in\n",
      "the\n",
      "future\n",
      "Fulton\n",
      "County\n",
      "should\n",
      "receive\n",
      "some\n",
      "portion\n",
      "of\n",
      "these\n",
      "available\n",
      "funds\n",
      "''\n",
      ",\n",
      "the\n",
      "jurors\n",
      "said\n",
      ".\n",
      "``\n",
      "Failure\n",
      "to\n",
      "do\n",
      "this\n",
      "will\n",
      "continue\n",
      "to\n",
      "place\n",
      "a\n",
      "disproportionate\n",
      "burden\n",
      "''\n",
      "on\n",
      "Fulton\n",
      "taxpayers\n",
      ".\n",
      "The\n",
      "jury\n",
      "also\n",
      "commented\n",
      "on\n",
      "the\n",
      "Fulton\n",
      "ordinary's\n",
      "court\n",
      "which\n",
      "has\n",
      "been\n"
     ]
    }
   ],
   "source": [
    "for i in arr[:500]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67d0a586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that any irregularities took place . The jury further said in term-end presentments that the City Executive Committee , which had over-all charge of the election , `` deserves the praise and thanks of the City of Atlanta '' for the manner in which the election was conducted . The September-October term jury had been charged by Fulton Superior Court Judge Durwood Pye to investigate reports of possible `` irregularities '' in the hard-fought primary which was won by Mayor-nominate Ivan Allen Jr. . `` Only a relative handful of such reports was received '' , the jury said , `` considering the widespread interest in the election , the number of voters and the size of this city '' . The jury said it did find that many of Georgia's registration and election laws `` are outmoded or inadequate and often ambiguous '' . It recommended that Fulton legislators act `` to have these laws studied and revised to the end of modernizing and improving them '' . The grand jury commented on a number of other topics , among them the Atlanta and Fulton County purchasing departments which it said `` are well operated and follow generally accepted practices which inure to the best interest of both governments '' . Merger proposed However , the jury said it believes `` these two offices should be combined to achieve greater efficiency and reduce the cost of administration '' . The City Purchasing Department , the jury said , `` is lacking in experienced clerical personnel as a result of city personnel policies '' . It urged that the city `` take steps to remedy '' this problem . Implementation of Georgia's automobile title law was also recommended by the outgoing jury . It urged that the next Legislature `` provide enabling funds and re-set the effective date so that an orderly implementation of the law may be effected '' . The grand jury took a swipe at the State Welfare Department's handling of federal funds granted for child welfare services in foster homes . `` This is one of the major items in the Fulton County general assistance program '' , the jury said , but the State Welfare Department `` has seen fit to distribute these funds through the welfare departments of all the counties in the state with the exception of Fulton County , which receives none of this money . The jurors said they realize `` a proportionate distribution of these funds might disable this program in our less populous counties '' . Nevertheless , `` we feel that in the future Fulton County should receive some portion of these available funds '' , the jurors said . `` Failure to do this will continue to place a disproportionate burden '' on Fulton taxpayers . The jury also commented on the Fulton ordinary's court which has been "
     ]
    }
   ],
   "source": [
    "for i in arr[:500]:\n",
    "    print(i ,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efbd023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "633165cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "print(gutenberg.fileids())   #if it is a folder then we can get the files name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1304ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2 = gutenberg.fileids()\n",
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87a15219",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gutenberg.words('shakespeare-macbeth.txt')  #get the file from the mensioned file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c0fc7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'The', 'Tragedie', 'of', 'Macbeth', 'by', ...]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01031146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ The Tragedie of Macbeth by William Shakespeare 1603 ] Actus Primus . Scoena Prima . Thunder and Lightning . Enter three Witches . 1 . When shall we three meet againe ? In Thunder , Lightning , or in Raine ? 2 . When the Hurley - burley ' s done , When the Battaile ' s lost , and wonne 3 . That will be ere the set of Sunne 1 . Where the place ? 2 . Vpon the Heath 3 . There to meet with Macbeth 1 . I come , Gray - Malkin All . Padock calls anon : faire is foule , and foule is faire , Houer through the fogge and filthie ayre . Exeunt . Scena Secunda . Alarum within . Enter King Malcome , Donalbaine , Lenox , with attendants , meeting a bleeding Captaine . King . What bloody man is that ? he can report , As seemeth by his plight , of the Reuolt The newest state Mal . This is the Serieant , Who like a good and hardie Souldier fought ' Gainst my Captiuitie : Haile braue friend ; Say to the King , the knowledge of the Broyle , As thou didst leaue it Cap . Doubtfull it stood , As two spent Swimmers , that doe cling together , And choake their Art : The mercilesse Macdonwald ( Worthie to be a Rebell , for to that The multiplying Villanies of Nature Doe swarme vpon him ) from the Westerne Isles Of Kernes and Gallowgrosses is supply ' d , And Fortune on his damned Quarry smiling , Shew ' d like a Rebells Whore : but all ' s too weake : For braue Macbeth ( well hee deserues that Name ) Disdayning Fortune , with his brandisht Steele , Which smoak ' d with bloody execution ( Like Valours Minion ) caru ' d out his passage , Till hee fac ' d the Slaue : Which neu ' r shooke hands , nor bad farwell to him , Till he vnseam ' d him from the Naue toth ' Chops , And fix ' d his Head vpon our Battlements King . O valiant Cousin , worthy Gentleman Cap . As whence the Sunne ' gins his reflection , Shipwracking Stormes , and direfull Thunders : So from that Spring , whence comfort seem ' d to come , Discomfort swells : Marke King of Scotland , marke , No sooner Iustice had , with Valour arm ' d , Compell ' d these skipping Kernes to trust their heeles , But the Norweyan Lord , surueying vantage , With furbusht Armes , and new supplyes of men , Began a fresh assault King . Dismay ' d not this our Captaines , Macbeth and Banquoh ? Cap . Yes , as Sparrowes , Eagles ; Or the Hare , the Lyon : If I say sooth , I must report "
     ]
    }
   ],
   "source": [
    "for i in data[:500]:\n",
    "    print(i ,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcc27873",
   "metadata": {},
   "outputs": [],
   "source": [
    "swami='''\n",
    "Born into an aristocratic Bengali Kayastha family of Calcutta,\n",
    "Vivekananda was inclined towards spirituality.\n",
    "\n",
    "He was influenced by his guru, Ramakrishna, from whom he learnt that\n",
    "all living beings were an embodiment of the divine self; therefore,\n",
    "service to God could be rendered by service to humankind.\n",
    "After Ramakrishna's death, Vivekananda toured the Indian subcontinent extensively and\n",
    "acquired first-hand knowledge of the conditions prevailing in British India.\n",
    "\n",
    "He later traveled to the United States, representing India at the 1893\n",
    "Parliament of the World's Religions. Vivekananda conducted hundreds of\n",
    "public and private lectures and classes, disseminating tenets of Hindu\n",
    "philosophy in the United States, England and Europe.\n",
    "\n",
    "In India, Vivekananda is regarded as a patriotic saint, and his birthday is celebrated as National Youth Day'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59908209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(swami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "381c7c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "546f871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "swami_tokens = word_tokenize(swami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b270893b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Born',\n",
       " 'into',\n",
       " 'an',\n",
       " 'aristocratic',\n",
       " 'Bengali',\n",
       " 'Kayastha',\n",
       " 'family',\n",
       " 'of',\n",
       " 'Calcutta',\n",
       " ',',\n",
       " 'Vivekananda',\n",
       " 'was',\n",
       " 'inclined',\n",
       " 'towards',\n",
       " 'spirituality',\n",
       " '.',\n",
       " 'He',\n",
       " 'was',\n",
       " 'influenced',\n",
       " 'by',\n",
       " 'his',\n",
       " 'guru',\n",
       " ',',\n",
       " 'Ramakrishna',\n",
       " ',',\n",
       " 'from',\n",
       " 'whom',\n",
       " 'he',\n",
       " 'learnt',\n",
       " 'that',\n",
       " 'all',\n",
       " 'living',\n",
       " 'beings',\n",
       " 'were',\n",
       " 'an',\n",
       " 'embodiment',\n",
       " 'of',\n",
       " 'the',\n",
       " 'divine',\n",
       " 'self',\n",
       " ';',\n",
       " 'therefore',\n",
       " ',',\n",
       " 'service',\n",
       " 'to',\n",
       " 'God',\n",
       " 'could',\n",
       " 'be',\n",
       " 'rendered',\n",
       " 'by',\n",
       " 'service',\n",
       " 'to',\n",
       " 'humankind',\n",
       " '.',\n",
       " 'After',\n",
       " 'Ramakrishna',\n",
       " \"'s\",\n",
       " 'death',\n",
       " ',',\n",
       " 'Vivekananda',\n",
       " 'toured',\n",
       " 'the',\n",
       " 'Indian',\n",
       " 'subcontinent',\n",
       " 'extensively',\n",
       " 'and',\n",
       " 'acquired',\n",
       " 'first-hand',\n",
       " 'knowledge',\n",
       " 'of',\n",
       " 'the',\n",
       " 'conditions',\n",
       " 'prevailing',\n",
       " 'in',\n",
       " 'British',\n",
       " 'India',\n",
       " '.',\n",
       " 'He',\n",
       " 'later',\n",
       " 'traveled',\n",
       " 'to',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " ',',\n",
       " 'representing',\n",
       " 'India',\n",
       " 'at',\n",
       " 'the',\n",
       " '1893',\n",
       " 'Parliament',\n",
       " 'of',\n",
       " 'the',\n",
       " 'World',\n",
       " \"'s\",\n",
       " 'Religions',\n",
       " '.',\n",
       " 'Vivekananda',\n",
       " 'conducted',\n",
       " 'hundreds',\n",
       " 'of',\n",
       " 'public',\n",
       " 'and',\n",
       " 'private',\n",
       " 'lectures',\n",
       " 'and',\n",
       " 'classes',\n",
       " ',',\n",
       " 'disseminating',\n",
       " 'tenets',\n",
       " 'of',\n",
       " 'Hindu',\n",
       " 'philosophy',\n",
       " 'in',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " ',',\n",
       " 'England',\n",
       " 'and',\n",
       " 'Europe',\n",
       " '.',\n",
       " 'In',\n",
       " 'India',\n",
       " ',',\n",
       " 'Vivekananda',\n",
       " 'is',\n",
       " 'regarded',\n",
       " 'as',\n",
       " 'a',\n",
       " 'patriotic',\n",
       " 'saint',\n",
       " ',',\n",
       " 'and',\n",
       " 'his',\n",
       " 'birthday',\n",
       " 'is',\n",
       " 'celebrated',\n",
       " 'as',\n",
       " 'National',\n",
       " 'Youth',\n",
       " 'Day']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swami_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43cce6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(swami_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc4a68a",
   "metadata": {},
   "source": [
    "# Count the Frequency of char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68b8ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist  # lib to count char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61e5dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist=FreqDist()  # object creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1569e07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 10, 'the': 7, 'of': 6, '.': 5, 'and': 5, 'vivekananda': 4, 'he': 3, 'to': 3, 'in': 3, 'india': 3, ...})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in swami_tokens:\n",
    "    fdist[word.lower()]+=1\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5972646f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist['vivekananda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e34f6453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10147f30",
   "metadata": {},
   "source": [
    "# Top ten (10) frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51d9f2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 10),\n",
       " ('the', 7),\n",
       " ('of', 6),\n",
       " ('.', 5),\n",
       " ('and', 5),\n",
       " ('vivekananda', 4),\n",
       " ('he', 3),\n",
       " ('to', 3),\n",
       " ('in', 3),\n",
       " ('india', 3)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10 = fdist.most_common(10)\n",
    "top10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a95209",
   "metadata": {},
   "source": [
    "# Least ten (10) frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0611e38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('europe', 1),\n",
       " ('regarded', 1),\n",
       " ('a', 1),\n",
       " ('patriotic', 1),\n",
       " ('saint', 1),\n",
       " ('birthday', 1),\n",
       " ('celebrated', 1),\n",
       " ('national', 1),\n",
       " ('youth', 1),\n",
       " ('day', 1)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "least10 = fdist.most_common()[-10:]\n",
    "least10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66312983",
   "metadata": {},
   "source": [
    "# Find Number of Blank Lines/Paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "069f7b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import blankline_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e247eaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "swami_blank=blankline_tokenize(swami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b39eb235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(swami_blank)   # we have 4 blank lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7dc02b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"He was influenced by his guru, Ramakrishna, from whom he learnt that\\nall living beings were an embodiment of the divine self; therefore,\\nservice to God could be rendered by service to humankind.\\nAfter Ramakrishna's death, Vivekananda toured the Indian subcontinent extensively and\\nacquired first-hand knowledge of the conditions prevailing in British India.\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swami_blank[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8096ad2f",
   "metadata": {},
   "source": [
    "# Sentance Tockenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0bd4821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text ='''\n",
    "Hello Mr. Naman, How are you? Welcome to our World.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "98d422af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e79d9575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nHello Mr. Naman, How are you?', 'Welcome to our World.']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_token = sent_tokenize(text)\n",
    "sen_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b6621e",
   "metadata": {},
   "source": [
    "# * Bigrams - Tokens of two consecutive written words known as bigrams.\n",
    "# * Trigrams - Tokens of three consecutive written words known as trigrams.\n",
    "# * Ngrams - Tokens of any number of consecutive written words known as Ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc404787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import bigrams, trigrams, ngrams\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0da80fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "string='''\n",
    "I think it's very important to have a feedback loop,\n",
    "where you're constantly thinking about what you've\n",
    "done and how you could be doing it better. I think that's\n",
    "the single best piece of advice: constantly think about how you\n",
    "could be doing things better and questioning yourself\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3c5aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=nltk.word_tokenize(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b1ce8bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'think',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'very',\n",
       " 'important',\n",
       " 'to',\n",
       " 'have',\n",
       " 'a',\n",
       " 'feedback',\n",
       " 'loop',\n",
       " ',',\n",
       " 'where',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'constantly',\n",
       " 'thinking',\n",
       " 'about',\n",
       " 'what',\n",
       " \"you've\",\n",
       " 'done',\n",
       " 'and',\n",
       " 'how',\n",
       " 'you',\n",
       " 'could',\n",
       " 'be',\n",
       " 'doing',\n",
       " 'it',\n",
       " 'better',\n",
       " '.',\n",
       " 'I',\n",
       " 'think',\n",
       " \"that's\",\n",
       " 'the',\n",
       " 'single',\n",
       " 'best',\n",
       " 'piece',\n",
       " 'of',\n",
       " 'advice',\n",
       " ':',\n",
       " 'constantly',\n",
       " 'think',\n",
       " 'about',\n",
       " 'how',\n",
       " 'you',\n",
       " 'could',\n",
       " 'be',\n",
       " 'doing',\n",
       " 'things',\n",
       " 'better',\n",
       " 'and',\n",
       " 'questioning',\n",
       " 'yourself']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0da229",
   "metadata": {},
   "source": [
    "# Bigram code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f30b9c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_bigrams=list(nltk.bigrams(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "745ee85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'think'),\n",
       " ('think', 'it'),\n",
       " ('it', \"'s\"),\n",
       " (\"'s\", 'very'),\n",
       " ('very', 'important'),\n",
       " ('important', 'to'),\n",
       " ('to', 'have'),\n",
       " ('have', 'a'),\n",
       " ('a', 'feedback'),\n",
       " ('feedback', 'loop'),\n",
       " ('loop', ','),\n",
       " (',', 'where'),\n",
       " ('where', 'you'),\n",
       " ('you', \"'re\"),\n",
       " (\"'re\", 'constantly'),\n",
       " ('constantly', 'thinking'),\n",
       " ('thinking', 'about'),\n",
       " ('about', 'what'),\n",
       " ('what', \"you've\"),\n",
       " (\"you've\", 'done'),\n",
       " ('done', 'and'),\n",
       " ('and', 'how'),\n",
       " ('how', 'you'),\n",
       " ('you', 'could'),\n",
       " ('could', 'be'),\n",
       " ('be', 'doing'),\n",
       " ('doing', 'it'),\n",
       " ('it', 'better'),\n",
       " ('better', '.'),\n",
       " ('.', 'I'),\n",
       " ('I', 'think'),\n",
       " ('think', \"that's\"),\n",
       " (\"that's\", 'the'),\n",
       " ('the', 'single'),\n",
       " ('single', 'best'),\n",
       " ('best', 'piece'),\n",
       " ('piece', 'of'),\n",
       " ('of', 'advice'),\n",
       " ('advice', ':'),\n",
       " (':', 'constantly'),\n",
       " ('constantly', 'think'),\n",
       " ('think', 'about'),\n",
       " ('about', 'how'),\n",
       " ('how', 'you'),\n",
       " ('you', 'could'),\n",
       " ('could', 'be'),\n",
       " ('be', 'doing'),\n",
       " ('doing', 'things'),\n",
       " ('things', 'better'),\n",
       " ('better', 'and'),\n",
       " ('and', 'questioning'),\n",
       " ('questioning', 'yourself')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c0d257",
   "metadata": {},
   "source": [
    "# Trigram code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a73cf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_trigrams=list(nltk.trigrams(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0581378d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'think', 'it'),\n",
       " ('think', 'it', \"'s\"),\n",
       " ('it', \"'s\", 'very'),\n",
       " (\"'s\", 'very', 'important'),\n",
       " ('very', 'important', 'to'),\n",
       " ('important', 'to', 'have'),\n",
       " ('to', 'have', 'a'),\n",
       " ('have', 'a', 'feedback'),\n",
       " ('a', 'feedback', 'loop'),\n",
       " ('feedback', 'loop', ','),\n",
       " ('loop', ',', 'where'),\n",
       " (',', 'where', 'you'),\n",
       " ('where', 'you', \"'re\"),\n",
       " ('you', \"'re\", 'constantly'),\n",
       " (\"'re\", 'constantly', 'thinking'),\n",
       " ('constantly', 'thinking', 'about'),\n",
       " ('thinking', 'about', 'what'),\n",
       " ('about', 'what', \"you've\"),\n",
       " ('what', \"you've\", 'done'),\n",
       " (\"you've\", 'done', 'and'),\n",
       " ('done', 'and', 'how'),\n",
       " ('and', 'how', 'you'),\n",
       " ('how', 'you', 'could'),\n",
       " ('you', 'could', 'be'),\n",
       " ('could', 'be', 'doing'),\n",
       " ('be', 'doing', 'it'),\n",
       " ('doing', 'it', 'better'),\n",
       " ('it', 'better', '.'),\n",
       " ('better', '.', 'I'),\n",
       " ('.', 'I', 'think'),\n",
       " ('I', 'think', \"that's\"),\n",
       " ('think', \"that's\", 'the'),\n",
       " (\"that's\", 'the', 'single'),\n",
       " ('the', 'single', 'best'),\n",
       " ('single', 'best', 'piece'),\n",
       " ('best', 'piece', 'of'),\n",
       " ('piece', 'of', 'advice'),\n",
       " ('of', 'advice', ':'),\n",
       " ('advice', ':', 'constantly'),\n",
       " (':', 'constantly', 'think'),\n",
       " ('constantly', 'think', 'about'),\n",
       " ('think', 'about', 'how'),\n",
       " ('about', 'how', 'you'),\n",
       " ('how', 'you', 'could'),\n",
       " ('you', 'could', 'be'),\n",
       " ('could', 'be', 'doing'),\n",
       " ('be', 'doing', 'things'),\n",
       " ('doing', 'things', 'better'),\n",
       " ('things', 'better', 'and'),\n",
       " ('better', 'and', 'questioning'),\n",
       " ('and', 'questioning', 'yourself')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488bdd78",
   "metadata": {},
   "source": [
    "# Ngram code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cf8e7b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ngrams=list(nltk.ngrams(t,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "81dc5eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'think', 'it', \"'s\", 'very'),\n",
       " ('think', 'it', \"'s\", 'very', 'important'),\n",
       " ('it', \"'s\", 'very', 'important', 'to'),\n",
       " (\"'s\", 'very', 'important', 'to', 'have'),\n",
       " ('very', 'important', 'to', 'have', 'a'),\n",
       " ('important', 'to', 'have', 'a', 'feedback'),\n",
       " ('to', 'have', 'a', 'feedback', 'loop'),\n",
       " ('have', 'a', 'feedback', 'loop', ','),\n",
       " ('a', 'feedback', 'loop', ',', 'where'),\n",
       " ('feedback', 'loop', ',', 'where', 'you'),\n",
       " ('loop', ',', 'where', 'you', \"'re\"),\n",
       " (',', 'where', 'you', \"'re\", 'constantly'),\n",
       " ('where', 'you', \"'re\", 'constantly', 'thinking'),\n",
       " ('you', \"'re\", 'constantly', 'thinking', 'about'),\n",
       " (\"'re\", 'constantly', 'thinking', 'about', 'what'),\n",
       " ('constantly', 'thinking', 'about', 'what', \"you've\"),\n",
       " ('thinking', 'about', 'what', \"you've\", 'done'),\n",
       " ('about', 'what', \"you've\", 'done', 'and'),\n",
       " ('what', \"you've\", 'done', 'and', 'how'),\n",
       " (\"you've\", 'done', 'and', 'how', 'you'),\n",
       " ('done', 'and', 'how', 'you', 'could'),\n",
       " ('and', 'how', 'you', 'could', 'be'),\n",
       " ('how', 'you', 'could', 'be', 'doing'),\n",
       " ('you', 'could', 'be', 'doing', 'it'),\n",
       " ('could', 'be', 'doing', 'it', 'better'),\n",
       " ('be', 'doing', 'it', 'better', '.'),\n",
       " ('doing', 'it', 'better', '.', 'I'),\n",
       " ('it', 'better', '.', 'I', 'think'),\n",
       " ('better', '.', 'I', 'think', \"that's\"),\n",
       " ('.', 'I', 'think', \"that's\", 'the'),\n",
       " ('I', 'think', \"that's\", 'the', 'single'),\n",
       " ('think', \"that's\", 'the', 'single', 'best'),\n",
       " (\"that's\", 'the', 'single', 'best', 'piece'),\n",
       " ('the', 'single', 'best', 'piece', 'of'),\n",
       " ('single', 'best', 'piece', 'of', 'advice'),\n",
       " ('best', 'piece', 'of', 'advice', ':'),\n",
       " ('piece', 'of', 'advice', ':', 'constantly'),\n",
       " ('of', 'advice', ':', 'constantly', 'think'),\n",
       " ('advice', ':', 'constantly', 'think', 'about'),\n",
       " (':', 'constantly', 'think', 'about', 'how'),\n",
       " ('constantly', 'think', 'about', 'how', 'you'),\n",
       " ('think', 'about', 'how', 'you', 'could'),\n",
       " ('about', 'how', 'you', 'could', 'be'),\n",
       " ('how', 'you', 'could', 'be', 'doing'),\n",
       " ('you', 'could', 'be', 'doing', 'things'),\n",
       " ('could', 'be', 'doing', 'things', 'better'),\n",
       " ('be', 'doing', 'things', 'better', 'and'),\n",
       " ('doing', 'things', 'better', 'and', 'questioning'),\n",
       " ('things', 'better', 'and', 'questioning', 'yourself')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04971124",
   "metadata": {},
   "source": [
    "# when we tockenize our text (like we tocknize strint to t) then our ngram work on tockens/words but if we want to work on char then we can simply pass the original string. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73735614",
   "metadata": {},
   "source": [
    "* Bigram At word Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f3b1331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_bigrams=list(nltk.bigrams(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ca837ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\n', 'I'),\n",
       " ('I', ' '),\n",
       " (' ', 't'),\n",
       " ('t', 'h'),\n",
       " ('h', 'i'),\n",
       " ('i', 'n'),\n",
       " ('n', 'k'),\n",
       " ('k', ' '),\n",
       " (' ', 'i'),\n",
       " ('i', 't'),\n",
       " ('t', \"'\"),\n",
       " (\"'\", 's'),\n",
       " ('s', ' '),\n",
       " (' ', 'v'),\n",
       " ('v', 'e'),\n",
       " ('e', 'r'),\n",
       " ('r', 'y'),\n",
       " ('y', ' '),\n",
       " (' ', 'i'),\n",
       " ('i', 'm'),\n",
       " ('m', 'p'),\n",
       " ('p', 'o'),\n",
       " ('o', 'r'),\n",
       " ('r', 't'),\n",
       " ('t', 'a'),\n",
       " ('a', 'n'),\n",
       " ('n', 't'),\n",
       " ('t', ' '),\n",
       " (' ', 't'),\n",
       " ('t', 'o'),\n",
       " ('o', ' '),\n",
       " (' ', 'h'),\n",
       " ('h', 'a'),\n",
       " ('a', 'v'),\n",
       " ('v', 'e'),\n",
       " ('e', ' '),\n",
       " (' ', 'a'),\n",
       " ('a', ' '),\n",
       " (' ', 'f'),\n",
       " ('f', 'e'),\n",
       " ('e', 'e'),\n",
       " ('e', 'd'),\n",
       " ('d', 'b'),\n",
       " ('b', 'a'),\n",
       " ('a', 'c'),\n",
       " ('c', 'k'),\n",
       " ('k', ' '),\n",
       " (' ', 'l'),\n",
       " ('l', 'o'),\n",
       " ('o', 'o'),\n",
       " ('o', 'p'),\n",
       " ('p', ','),\n",
       " (',', '\\n'),\n",
       " ('\\n', 'w'),\n",
       " ('w', 'h'),\n",
       " ('h', 'e'),\n",
       " ('e', 'r'),\n",
       " ('r', 'e'),\n",
       " ('e', ' '),\n",
       " (' ', 'y'),\n",
       " ('y', 'o'),\n",
       " ('o', 'u'),\n",
       " ('u', \"'\"),\n",
       " (\"'\", 'r'),\n",
       " ('r', 'e'),\n",
       " ('e', ' '),\n",
       " (' ', 'c'),\n",
       " ('c', 'o'),\n",
       " ('o', 'n'),\n",
       " ('n', 's'),\n",
       " ('s', 't'),\n",
       " ('t', 'a'),\n",
       " ('a', 'n'),\n",
       " ('n', 't'),\n",
       " ('t', 'l'),\n",
       " ('l', 'y'),\n",
       " ('y', ' '),\n",
       " (' ', 't'),\n",
       " ('t', 'h'),\n",
       " ('h', 'i'),\n",
       " ('i', 'n'),\n",
       " ('n', 'k'),\n",
       " ('k', 'i'),\n",
       " ('i', 'n'),\n",
       " ('n', 'g'),\n",
       " ('g', ' '),\n",
       " (' ', 'a'),\n",
       " ('a', 'b'),\n",
       " ('b', 'o'),\n",
       " ('o', 'u'),\n",
       " ('u', 't'),\n",
       " ('t', ' '),\n",
       " (' ', 'w'),\n",
       " ('w', 'h'),\n",
       " ('h', 'a'),\n",
       " ('a', 't'),\n",
       " ('t', ' '),\n",
       " (' ', 'y'),\n",
       " ('y', 'o'),\n",
       " ('o', 'u'),\n",
       " ('u', \"'\"),\n",
       " (\"'\", 'v'),\n",
       " ('v', 'e'),\n",
       " ('e', '\\n'),\n",
       " ('\\n', 'd'),\n",
       " ('d', 'o'),\n",
       " ('o', 'n'),\n",
       " ('n', 'e'),\n",
       " ('e', ' '),\n",
       " (' ', 'a'),\n",
       " ('a', 'n'),\n",
       " ('n', 'd'),\n",
       " ('d', ' '),\n",
       " (' ', 'h'),\n",
       " ('h', 'o'),\n",
       " ('o', 'w'),\n",
       " ('w', ' '),\n",
       " (' ', 'y'),\n",
       " ('y', 'o'),\n",
       " ('o', 'u'),\n",
       " ('u', ' '),\n",
       " (' ', 'c'),\n",
       " ('c', 'o'),\n",
       " ('o', 'u'),\n",
       " ('u', 'l'),\n",
       " ('l', 'd'),\n",
       " ('d', ' '),\n",
       " (' ', 'b'),\n",
       " ('b', 'e'),\n",
       " ('e', ' '),\n",
       " (' ', 'd'),\n",
       " ('d', 'o'),\n",
       " ('o', 'i'),\n",
       " ('i', 'n'),\n",
       " ('n', 'g'),\n",
       " ('g', ' '),\n",
       " (' ', 'i'),\n",
       " ('i', 't'),\n",
       " ('t', ' '),\n",
       " (' ', 'b'),\n",
       " ('b', 'e'),\n",
       " ('e', 't'),\n",
       " ('t', 't'),\n",
       " ('t', 'e'),\n",
       " ('e', 'r'),\n",
       " ('r', '.'),\n",
       " ('.', ' '),\n",
       " (' ', 'I'),\n",
       " ('I', ' '),\n",
       " (' ', 't'),\n",
       " ('t', 'h'),\n",
       " ('h', 'i'),\n",
       " ('i', 'n'),\n",
       " ('n', 'k'),\n",
       " ('k', ' '),\n",
       " (' ', 't'),\n",
       " ('t', 'h'),\n",
       " ('h', 'a'),\n",
       " ('a', 't'),\n",
       " ('t', \"'\"),\n",
       " (\"'\", 's'),\n",
       " ('s', '\\n'),\n",
       " ('\\n', 't'),\n",
       " ('t', 'h'),\n",
       " ('h', 'e'),\n",
       " ('e', ' '),\n",
       " (' ', 's'),\n",
       " ('s', 'i'),\n",
       " ('i', 'n'),\n",
       " ('n', 'g'),\n",
       " ('g', 'l'),\n",
       " ('l', 'e'),\n",
       " ('e', ' '),\n",
       " (' ', 'b'),\n",
       " ('b', 'e'),\n",
       " ('e', 's'),\n",
       " ('s', 't'),\n",
       " ('t', ' '),\n",
       " (' ', 'p'),\n",
       " ('p', 'i'),\n",
       " ('i', 'e'),\n",
       " ('e', 'c'),\n",
       " ('c', 'e'),\n",
       " ('e', ' '),\n",
       " (' ', 'o'),\n",
       " ('o', 'f'),\n",
       " ('f', ' '),\n",
       " (' ', 'a'),\n",
       " ('a', 'd'),\n",
       " ('d', 'v'),\n",
       " ('v', 'i'),\n",
       " ('i', 'c'),\n",
       " ('c', 'e'),\n",
       " ('e', ':'),\n",
       " (':', ' '),\n",
       " (' ', 'c'),\n",
       " ('c', 'o'),\n",
       " ('o', 'n'),\n",
       " ('n', 's'),\n",
       " ('s', 't'),\n",
       " ('t', 'a'),\n",
       " ('a', 'n'),\n",
       " ('n', 't'),\n",
       " ('t', 'l'),\n",
       " ('l', 'y'),\n",
       " ('y', ' '),\n",
       " (' ', 't'),\n",
       " ('t', 'h'),\n",
       " ('h', 'i'),\n",
       " ('i', 'n'),\n",
       " ('n', 'k'),\n",
       " ('k', ' '),\n",
       " (' ', 'a'),\n",
       " ('a', 'b'),\n",
       " ('b', 'o'),\n",
       " ('o', 'u'),\n",
       " ('u', 't'),\n",
       " ('t', ' '),\n",
       " (' ', 'h'),\n",
       " ('h', 'o'),\n",
       " ('o', 'w'),\n",
       " ('w', ' '),\n",
       " (' ', 'y'),\n",
       " ('y', 'o'),\n",
       " ('o', 'u'),\n",
       " ('u', '\\n'),\n",
       " ('\\n', 'c'),\n",
       " ('c', 'o'),\n",
       " ('o', 'u'),\n",
       " ('u', 'l'),\n",
       " ('l', 'd'),\n",
       " ('d', ' '),\n",
       " (' ', 'b'),\n",
       " ('b', 'e'),\n",
       " ('e', ' '),\n",
       " (' ', 'd'),\n",
       " ('d', 'o'),\n",
       " ('o', 'i'),\n",
       " ('i', 'n'),\n",
       " ('n', 'g'),\n",
       " ('g', ' '),\n",
       " (' ', 't'),\n",
       " ('t', 'h'),\n",
       " ('h', 'i'),\n",
       " ('i', 'n'),\n",
       " ('n', 'g'),\n",
       " ('g', 's'),\n",
       " ('s', ' '),\n",
       " (' ', 'b'),\n",
       " ('b', 'e'),\n",
       " ('e', 't'),\n",
       " ('t', 't'),\n",
       " ('t', 'e'),\n",
       " ('e', 'r'),\n",
       " ('r', ' '),\n",
       " (' ', 'a'),\n",
       " ('a', 'n'),\n",
       " ('n', 'd'),\n",
       " ('d', ' '),\n",
       " (' ', 'q'),\n",
       " ('q', 'u'),\n",
       " ('u', 'e'),\n",
       " ('e', 's'),\n",
       " ('s', 't'),\n",
       " ('t', 'i'),\n",
       " ('i', 'o'),\n",
       " ('o', 'n'),\n",
       " ('n', 'i'),\n",
       " ('i', 'n'),\n",
       " ('n', 'g'),\n",
       " ('g', ' '),\n",
       " (' ', 'y'),\n",
       " ('y', 'o'),\n",
       " ('o', 'u'),\n",
       " ('u', 'r'),\n",
       " ('r', 's'),\n",
       " ('s', 'e'),\n",
       " ('e', 'l'),\n",
       " ('l', 'f'),\n",
       " ('f', '\\n')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab9e46",
   "metadata": {},
   "source": [
    "* Trigram At word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b8b5fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_trigrams=list(nltk.trigrams(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "912e48b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\n', 'I', ' '),\n",
       " ('I', ' ', 't'),\n",
       " (' ', 't', 'h'),\n",
       " ('t', 'h', 'i'),\n",
       " ('h', 'i', 'n'),\n",
       " ('i', 'n', 'k'),\n",
       " ('n', 'k', ' '),\n",
       " ('k', ' ', 'i'),\n",
       " (' ', 'i', 't'),\n",
       " ('i', 't', \"'\"),\n",
       " ('t', \"'\", 's'),\n",
       " (\"'\", 's', ' '),\n",
       " ('s', ' ', 'v'),\n",
       " (' ', 'v', 'e'),\n",
       " ('v', 'e', 'r'),\n",
       " ('e', 'r', 'y'),\n",
       " ('r', 'y', ' '),\n",
       " ('y', ' ', 'i'),\n",
       " (' ', 'i', 'm'),\n",
       " ('i', 'm', 'p'),\n",
       " ('m', 'p', 'o'),\n",
       " ('p', 'o', 'r'),\n",
       " ('o', 'r', 't'),\n",
       " ('r', 't', 'a'),\n",
       " ('t', 'a', 'n'),\n",
       " ('a', 'n', 't'),\n",
       " ('n', 't', ' '),\n",
       " ('t', ' ', 't'),\n",
       " (' ', 't', 'o'),\n",
       " ('t', 'o', ' '),\n",
       " ('o', ' ', 'h'),\n",
       " (' ', 'h', 'a'),\n",
       " ('h', 'a', 'v'),\n",
       " ('a', 'v', 'e'),\n",
       " ('v', 'e', ' '),\n",
       " ('e', ' ', 'a'),\n",
       " (' ', 'a', ' '),\n",
       " ('a', ' ', 'f'),\n",
       " (' ', 'f', 'e'),\n",
       " ('f', 'e', 'e'),\n",
       " ('e', 'e', 'd'),\n",
       " ('e', 'd', 'b'),\n",
       " ('d', 'b', 'a'),\n",
       " ('b', 'a', 'c'),\n",
       " ('a', 'c', 'k'),\n",
       " ('c', 'k', ' '),\n",
       " ('k', ' ', 'l'),\n",
       " (' ', 'l', 'o'),\n",
       " ('l', 'o', 'o'),\n",
       " ('o', 'o', 'p'),\n",
       " ('o', 'p', ','),\n",
       " ('p', ',', '\\n'),\n",
       " (',', '\\n', 'w'),\n",
       " ('\\n', 'w', 'h'),\n",
       " ('w', 'h', 'e'),\n",
       " ('h', 'e', 'r'),\n",
       " ('e', 'r', 'e'),\n",
       " ('r', 'e', ' '),\n",
       " ('e', ' ', 'y'),\n",
       " (' ', 'y', 'o'),\n",
       " ('y', 'o', 'u'),\n",
       " ('o', 'u', \"'\"),\n",
       " ('u', \"'\", 'r'),\n",
       " (\"'\", 'r', 'e'),\n",
       " ('r', 'e', ' '),\n",
       " ('e', ' ', 'c'),\n",
       " (' ', 'c', 'o'),\n",
       " ('c', 'o', 'n'),\n",
       " ('o', 'n', 's'),\n",
       " ('n', 's', 't'),\n",
       " ('s', 't', 'a'),\n",
       " ('t', 'a', 'n'),\n",
       " ('a', 'n', 't'),\n",
       " ('n', 't', 'l'),\n",
       " ('t', 'l', 'y'),\n",
       " ('l', 'y', ' '),\n",
       " ('y', ' ', 't'),\n",
       " (' ', 't', 'h'),\n",
       " ('t', 'h', 'i'),\n",
       " ('h', 'i', 'n'),\n",
       " ('i', 'n', 'k'),\n",
       " ('n', 'k', 'i'),\n",
       " ('k', 'i', 'n'),\n",
       " ('i', 'n', 'g'),\n",
       " ('n', 'g', ' '),\n",
       " ('g', ' ', 'a'),\n",
       " (' ', 'a', 'b'),\n",
       " ('a', 'b', 'o'),\n",
       " ('b', 'o', 'u'),\n",
       " ('o', 'u', 't'),\n",
       " ('u', 't', ' '),\n",
       " ('t', ' ', 'w'),\n",
       " (' ', 'w', 'h'),\n",
       " ('w', 'h', 'a'),\n",
       " ('h', 'a', 't'),\n",
       " ('a', 't', ' '),\n",
       " ('t', ' ', 'y'),\n",
       " (' ', 'y', 'o'),\n",
       " ('y', 'o', 'u'),\n",
       " ('o', 'u', \"'\"),\n",
       " ('u', \"'\", 'v'),\n",
       " (\"'\", 'v', 'e'),\n",
       " ('v', 'e', '\\n'),\n",
       " ('e', '\\n', 'd'),\n",
       " ('\\n', 'd', 'o'),\n",
       " ('d', 'o', 'n'),\n",
       " ('o', 'n', 'e'),\n",
       " ('n', 'e', ' '),\n",
       " ('e', ' ', 'a'),\n",
       " (' ', 'a', 'n'),\n",
       " ('a', 'n', 'd'),\n",
       " ('n', 'd', ' '),\n",
       " ('d', ' ', 'h'),\n",
       " (' ', 'h', 'o'),\n",
       " ('h', 'o', 'w'),\n",
       " ('o', 'w', ' '),\n",
       " ('w', ' ', 'y'),\n",
       " (' ', 'y', 'o'),\n",
       " ('y', 'o', 'u'),\n",
       " ('o', 'u', ' '),\n",
       " ('u', ' ', 'c'),\n",
       " (' ', 'c', 'o'),\n",
       " ('c', 'o', 'u'),\n",
       " ('o', 'u', 'l'),\n",
       " ('u', 'l', 'd'),\n",
       " ('l', 'd', ' '),\n",
       " ('d', ' ', 'b'),\n",
       " (' ', 'b', 'e'),\n",
       " ('b', 'e', ' '),\n",
       " ('e', ' ', 'd'),\n",
       " (' ', 'd', 'o'),\n",
       " ('d', 'o', 'i'),\n",
       " ('o', 'i', 'n'),\n",
       " ('i', 'n', 'g'),\n",
       " ('n', 'g', ' '),\n",
       " ('g', ' ', 'i'),\n",
       " (' ', 'i', 't'),\n",
       " ('i', 't', ' '),\n",
       " ('t', ' ', 'b'),\n",
       " (' ', 'b', 'e'),\n",
       " ('b', 'e', 't'),\n",
       " ('e', 't', 't'),\n",
       " ('t', 't', 'e'),\n",
       " ('t', 'e', 'r'),\n",
       " ('e', 'r', '.'),\n",
       " ('r', '.', ' '),\n",
       " ('.', ' ', 'I'),\n",
       " (' ', 'I', ' '),\n",
       " ('I', ' ', 't'),\n",
       " (' ', 't', 'h'),\n",
       " ('t', 'h', 'i'),\n",
       " ('h', 'i', 'n'),\n",
       " ('i', 'n', 'k'),\n",
       " ('n', 'k', ' '),\n",
       " ('k', ' ', 't'),\n",
       " (' ', 't', 'h'),\n",
       " ('t', 'h', 'a'),\n",
       " ('h', 'a', 't'),\n",
       " ('a', 't', \"'\"),\n",
       " ('t', \"'\", 's'),\n",
       " (\"'\", 's', '\\n'),\n",
       " ('s', '\\n', 't'),\n",
       " ('\\n', 't', 'h'),\n",
       " ('t', 'h', 'e'),\n",
       " ('h', 'e', ' '),\n",
       " ('e', ' ', 's'),\n",
       " (' ', 's', 'i'),\n",
       " ('s', 'i', 'n'),\n",
       " ('i', 'n', 'g'),\n",
       " ('n', 'g', 'l'),\n",
       " ('g', 'l', 'e'),\n",
       " ('l', 'e', ' '),\n",
       " ('e', ' ', 'b'),\n",
       " (' ', 'b', 'e'),\n",
       " ('b', 'e', 's'),\n",
       " ('e', 's', 't'),\n",
       " ('s', 't', ' '),\n",
       " ('t', ' ', 'p'),\n",
       " (' ', 'p', 'i'),\n",
       " ('p', 'i', 'e'),\n",
       " ('i', 'e', 'c'),\n",
       " ('e', 'c', 'e'),\n",
       " ('c', 'e', ' '),\n",
       " ('e', ' ', 'o'),\n",
       " (' ', 'o', 'f'),\n",
       " ('o', 'f', ' '),\n",
       " ('f', ' ', 'a'),\n",
       " (' ', 'a', 'd'),\n",
       " ('a', 'd', 'v'),\n",
       " ('d', 'v', 'i'),\n",
       " ('v', 'i', 'c'),\n",
       " ('i', 'c', 'e'),\n",
       " ('c', 'e', ':'),\n",
       " ('e', ':', ' '),\n",
       " (':', ' ', 'c'),\n",
       " (' ', 'c', 'o'),\n",
       " ('c', 'o', 'n'),\n",
       " ('o', 'n', 's'),\n",
       " ('n', 's', 't'),\n",
       " ('s', 't', 'a'),\n",
       " ('t', 'a', 'n'),\n",
       " ('a', 'n', 't'),\n",
       " ('n', 't', 'l'),\n",
       " ('t', 'l', 'y'),\n",
       " ('l', 'y', ' '),\n",
       " ('y', ' ', 't'),\n",
       " (' ', 't', 'h'),\n",
       " ('t', 'h', 'i'),\n",
       " ('h', 'i', 'n'),\n",
       " ('i', 'n', 'k'),\n",
       " ('n', 'k', ' '),\n",
       " ('k', ' ', 'a'),\n",
       " (' ', 'a', 'b'),\n",
       " ('a', 'b', 'o'),\n",
       " ('b', 'o', 'u'),\n",
       " ('o', 'u', 't'),\n",
       " ('u', 't', ' '),\n",
       " ('t', ' ', 'h'),\n",
       " (' ', 'h', 'o'),\n",
       " ('h', 'o', 'w'),\n",
       " ('o', 'w', ' '),\n",
       " ('w', ' ', 'y'),\n",
       " (' ', 'y', 'o'),\n",
       " ('y', 'o', 'u'),\n",
       " ('o', 'u', '\\n'),\n",
       " ('u', '\\n', 'c'),\n",
       " ('\\n', 'c', 'o'),\n",
       " ('c', 'o', 'u'),\n",
       " ('o', 'u', 'l'),\n",
       " ('u', 'l', 'd'),\n",
       " ('l', 'd', ' '),\n",
       " ('d', ' ', 'b'),\n",
       " (' ', 'b', 'e'),\n",
       " ('b', 'e', ' '),\n",
       " ('e', ' ', 'd'),\n",
       " (' ', 'd', 'o'),\n",
       " ('d', 'o', 'i'),\n",
       " ('o', 'i', 'n'),\n",
       " ('i', 'n', 'g'),\n",
       " ('n', 'g', ' '),\n",
       " ('g', ' ', 't'),\n",
       " (' ', 't', 'h'),\n",
       " ('t', 'h', 'i'),\n",
       " ('h', 'i', 'n'),\n",
       " ('i', 'n', 'g'),\n",
       " ('n', 'g', 's'),\n",
       " ('g', 's', ' '),\n",
       " ('s', ' ', 'b'),\n",
       " (' ', 'b', 'e'),\n",
       " ('b', 'e', 't'),\n",
       " ('e', 't', 't'),\n",
       " ('t', 't', 'e'),\n",
       " ('t', 'e', 'r'),\n",
       " ('e', 'r', ' '),\n",
       " ('r', ' ', 'a'),\n",
       " (' ', 'a', 'n'),\n",
       " ('a', 'n', 'd'),\n",
       " ('n', 'd', ' '),\n",
       " ('d', ' ', 'q'),\n",
       " (' ', 'q', 'u'),\n",
       " ('q', 'u', 'e'),\n",
       " ('u', 'e', 's'),\n",
       " ('e', 's', 't'),\n",
       " ('s', 't', 'i'),\n",
       " ('t', 'i', 'o'),\n",
       " ('i', 'o', 'n'),\n",
       " ('o', 'n', 'i'),\n",
       " ('n', 'i', 'n'),\n",
       " ('i', 'n', 'g'),\n",
       " ('n', 'g', ' '),\n",
       " ('g', ' ', 'y'),\n",
       " (' ', 'y', 'o'),\n",
       " ('y', 'o', 'u'),\n",
       " ('o', 'u', 'r'),\n",
       " ('u', 'r', 's'),\n",
       " ('r', 's', 'e'),\n",
       " ('s', 'e', 'l'),\n",
       " ('e', 'l', 'f'),\n",
       " ('l', 'f', '\\n')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d0e33a",
   "metadata": {},
   "source": [
    "* ngram at word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2b13bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ngrams=list(nltk.ngrams(string,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e68028a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\n', 'I', ' ', 't', 'h'),\n",
       " ('I', ' ', 't', 'h', 'i'),\n",
       " (' ', 't', 'h', 'i', 'n'),\n",
       " ('t', 'h', 'i', 'n', 'k'),\n",
       " ('h', 'i', 'n', 'k', ' '),\n",
       " ('i', 'n', 'k', ' ', 'i'),\n",
       " ('n', 'k', ' ', 'i', 't'),\n",
       " ('k', ' ', 'i', 't', \"'\"),\n",
       " (' ', 'i', 't', \"'\", 's'),\n",
       " ('i', 't', \"'\", 's', ' '),\n",
       " ('t', \"'\", 's', ' ', 'v'),\n",
       " (\"'\", 's', ' ', 'v', 'e'),\n",
       " ('s', ' ', 'v', 'e', 'r'),\n",
       " (' ', 'v', 'e', 'r', 'y'),\n",
       " ('v', 'e', 'r', 'y', ' '),\n",
       " ('e', 'r', 'y', ' ', 'i'),\n",
       " ('r', 'y', ' ', 'i', 'm'),\n",
       " ('y', ' ', 'i', 'm', 'p'),\n",
       " (' ', 'i', 'm', 'p', 'o'),\n",
       " ('i', 'm', 'p', 'o', 'r'),\n",
       " ('m', 'p', 'o', 'r', 't'),\n",
       " ('p', 'o', 'r', 't', 'a'),\n",
       " ('o', 'r', 't', 'a', 'n'),\n",
       " ('r', 't', 'a', 'n', 't'),\n",
       " ('t', 'a', 'n', 't', ' '),\n",
       " ('a', 'n', 't', ' ', 't'),\n",
       " ('n', 't', ' ', 't', 'o'),\n",
       " ('t', ' ', 't', 'o', ' '),\n",
       " (' ', 't', 'o', ' ', 'h'),\n",
       " ('t', 'o', ' ', 'h', 'a'),\n",
       " ('o', ' ', 'h', 'a', 'v'),\n",
       " (' ', 'h', 'a', 'v', 'e'),\n",
       " ('h', 'a', 'v', 'e', ' '),\n",
       " ('a', 'v', 'e', ' ', 'a'),\n",
       " ('v', 'e', ' ', 'a', ' '),\n",
       " ('e', ' ', 'a', ' ', 'f'),\n",
       " (' ', 'a', ' ', 'f', 'e'),\n",
       " ('a', ' ', 'f', 'e', 'e'),\n",
       " (' ', 'f', 'e', 'e', 'd'),\n",
       " ('f', 'e', 'e', 'd', 'b'),\n",
       " ('e', 'e', 'd', 'b', 'a'),\n",
       " ('e', 'd', 'b', 'a', 'c'),\n",
       " ('d', 'b', 'a', 'c', 'k'),\n",
       " ('b', 'a', 'c', 'k', ' '),\n",
       " ('a', 'c', 'k', ' ', 'l'),\n",
       " ('c', 'k', ' ', 'l', 'o'),\n",
       " ('k', ' ', 'l', 'o', 'o'),\n",
       " (' ', 'l', 'o', 'o', 'p'),\n",
       " ('l', 'o', 'o', 'p', ','),\n",
       " ('o', 'o', 'p', ',', '\\n'),\n",
       " ('o', 'p', ',', '\\n', 'w'),\n",
       " ('p', ',', '\\n', 'w', 'h'),\n",
       " (',', '\\n', 'w', 'h', 'e'),\n",
       " ('\\n', 'w', 'h', 'e', 'r'),\n",
       " ('w', 'h', 'e', 'r', 'e'),\n",
       " ('h', 'e', 'r', 'e', ' '),\n",
       " ('e', 'r', 'e', ' ', 'y'),\n",
       " ('r', 'e', ' ', 'y', 'o'),\n",
       " ('e', ' ', 'y', 'o', 'u'),\n",
       " (' ', 'y', 'o', 'u', \"'\"),\n",
       " ('y', 'o', 'u', \"'\", 'r'),\n",
       " ('o', 'u', \"'\", 'r', 'e'),\n",
       " ('u', \"'\", 'r', 'e', ' '),\n",
       " (\"'\", 'r', 'e', ' ', 'c'),\n",
       " ('r', 'e', ' ', 'c', 'o'),\n",
       " ('e', ' ', 'c', 'o', 'n'),\n",
       " (' ', 'c', 'o', 'n', 's'),\n",
       " ('c', 'o', 'n', 's', 't'),\n",
       " ('o', 'n', 's', 't', 'a'),\n",
       " ('n', 's', 't', 'a', 'n'),\n",
       " ('s', 't', 'a', 'n', 't'),\n",
       " ('t', 'a', 'n', 't', 'l'),\n",
       " ('a', 'n', 't', 'l', 'y'),\n",
       " ('n', 't', 'l', 'y', ' '),\n",
       " ('t', 'l', 'y', ' ', 't'),\n",
       " ('l', 'y', ' ', 't', 'h'),\n",
       " ('y', ' ', 't', 'h', 'i'),\n",
       " (' ', 't', 'h', 'i', 'n'),\n",
       " ('t', 'h', 'i', 'n', 'k'),\n",
       " ('h', 'i', 'n', 'k', 'i'),\n",
       " ('i', 'n', 'k', 'i', 'n'),\n",
       " ('n', 'k', 'i', 'n', 'g'),\n",
       " ('k', 'i', 'n', 'g', ' '),\n",
       " ('i', 'n', 'g', ' ', 'a'),\n",
       " ('n', 'g', ' ', 'a', 'b'),\n",
       " ('g', ' ', 'a', 'b', 'o'),\n",
       " (' ', 'a', 'b', 'o', 'u'),\n",
       " ('a', 'b', 'o', 'u', 't'),\n",
       " ('b', 'o', 'u', 't', ' '),\n",
       " ('o', 'u', 't', ' ', 'w'),\n",
       " ('u', 't', ' ', 'w', 'h'),\n",
       " ('t', ' ', 'w', 'h', 'a'),\n",
       " (' ', 'w', 'h', 'a', 't'),\n",
       " ('w', 'h', 'a', 't', ' '),\n",
       " ('h', 'a', 't', ' ', 'y'),\n",
       " ('a', 't', ' ', 'y', 'o'),\n",
       " ('t', ' ', 'y', 'o', 'u'),\n",
       " (' ', 'y', 'o', 'u', \"'\"),\n",
       " ('y', 'o', 'u', \"'\", 'v'),\n",
       " ('o', 'u', \"'\", 'v', 'e'),\n",
       " ('u', \"'\", 'v', 'e', '\\n'),\n",
       " (\"'\", 'v', 'e', '\\n', 'd'),\n",
       " ('v', 'e', '\\n', 'd', 'o'),\n",
       " ('e', '\\n', 'd', 'o', 'n'),\n",
       " ('\\n', 'd', 'o', 'n', 'e'),\n",
       " ('d', 'o', 'n', 'e', ' '),\n",
       " ('o', 'n', 'e', ' ', 'a'),\n",
       " ('n', 'e', ' ', 'a', 'n'),\n",
       " ('e', ' ', 'a', 'n', 'd'),\n",
       " (' ', 'a', 'n', 'd', ' '),\n",
       " ('a', 'n', 'd', ' ', 'h'),\n",
       " ('n', 'd', ' ', 'h', 'o'),\n",
       " ('d', ' ', 'h', 'o', 'w'),\n",
       " (' ', 'h', 'o', 'w', ' '),\n",
       " ('h', 'o', 'w', ' ', 'y'),\n",
       " ('o', 'w', ' ', 'y', 'o'),\n",
       " ('w', ' ', 'y', 'o', 'u'),\n",
       " (' ', 'y', 'o', 'u', ' '),\n",
       " ('y', 'o', 'u', ' ', 'c'),\n",
       " ('o', 'u', ' ', 'c', 'o'),\n",
       " ('u', ' ', 'c', 'o', 'u'),\n",
       " (' ', 'c', 'o', 'u', 'l'),\n",
       " ('c', 'o', 'u', 'l', 'd'),\n",
       " ('o', 'u', 'l', 'd', ' '),\n",
       " ('u', 'l', 'd', ' ', 'b'),\n",
       " ('l', 'd', ' ', 'b', 'e'),\n",
       " ('d', ' ', 'b', 'e', ' '),\n",
       " (' ', 'b', 'e', ' ', 'd'),\n",
       " ('b', 'e', ' ', 'd', 'o'),\n",
       " ('e', ' ', 'd', 'o', 'i'),\n",
       " (' ', 'd', 'o', 'i', 'n'),\n",
       " ('d', 'o', 'i', 'n', 'g'),\n",
       " ('o', 'i', 'n', 'g', ' '),\n",
       " ('i', 'n', 'g', ' ', 'i'),\n",
       " ('n', 'g', ' ', 'i', 't'),\n",
       " ('g', ' ', 'i', 't', ' '),\n",
       " (' ', 'i', 't', ' ', 'b'),\n",
       " ('i', 't', ' ', 'b', 'e'),\n",
       " ('t', ' ', 'b', 'e', 't'),\n",
       " (' ', 'b', 'e', 't', 't'),\n",
       " ('b', 'e', 't', 't', 'e'),\n",
       " ('e', 't', 't', 'e', 'r'),\n",
       " ('t', 't', 'e', 'r', '.'),\n",
       " ('t', 'e', 'r', '.', ' '),\n",
       " ('e', 'r', '.', ' ', 'I'),\n",
       " ('r', '.', ' ', 'I', ' '),\n",
       " ('.', ' ', 'I', ' ', 't'),\n",
       " (' ', 'I', ' ', 't', 'h'),\n",
       " ('I', ' ', 't', 'h', 'i'),\n",
       " (' ', 't', 'h', 'i', 'n'),\n",
       " ('t', 'h', 'i', 'n', 'k'),\n",
       " ('h', 'i', 'n', 'k', ' '),\n",
       " ('i', 'n', 'k', ' ', 't'),\n",
       " ('n', 'k', ' ', 't', 'h'),\n",
       " ('k', ' ', 't', 'h', 'a'),\n",
       " (' ', 't', 'h', 'a', 't'),\n",
       " ('t', 'h', 'a', 't', \"'\"),\n",
       " ('h', 'a', 't', \"'\", 's'),\n",
       " ('a', 't', \"'\", 's', '\\n'),\n",
       " ('t', \"'\", 's', '\\n', 't'),\n",
       " (\"'\", 's', '\\n', 't', 'h'),\n",
       " ('s', '\\n', 't', 'h', 'e'),\n",
       " ('\\n', 't', 'h', 'e', ' '),\n",
       " ('t', 'h', 'e', ' ', 's'),\n",
       " ('h', 'e', ' ', 's', 'i'),\n",
       " ('e', ' ', 's', 'i', 'n'),\n",
       " (' ', 's', 'i', 'n', 'g'),\n",
       " ('s', 'i', 'n', 'g', 'l'),\n",
       " ('i', 'n', 'g', 'l', 'e'),\n",
       " ('n', 'g', 'l', 'e', ' '),\n",
       " ('g', 'l', 'e', ' ', 'b'),\n",
       " ('l', 'e', ' ', 'b', 'e'),\n",
       " ('e', ' ', 'b', 'e', 's'),\n",
       " (' ', 'b', 'e', 's', 't'),\n",
       " ('b', 'e', 's', 't', ' '),\n",
       " ('e', 's', 't', ' ', 'p'),\n",
       " ('s', 't', ' ', 'p', 'i'),\n",
       " ('t', ' ', 'p', 'i', 'e'),\n",
       " (' ', 'p', 'i', 'e', 'c'),\n",
       " ('p', 'i', 'e', 'c', 'e'),\n",
       " ('i', 'e', 'c', 'e', ' '),\n",
       " ('e', 'c', 'e', ' ', 'o'),\n",
       " ('c', 'e', ' ', 'o', 'f'),\n",
       " ('e', ' ', 'o', 'f', ' '),\n",
       " (' ', 'o', 'f', ' ', 'a'),\n",
       " ('o', 'f', ' ', 'a', 'd'),\n",
       " ('f', ' ', 'a', 'd', 'v'),\n",
       " (' ', 'a', 'd', 'v', 'i'),\n",
       " ('a', 'd', 'v', 'i', 'c'),\n",
       " ('d', 'v', 'i', 'c', 'e'),\n",
       " ('v', 'i', 'c', 'e', ':'),\n",
       " ('i', 'c', 'e', ':', ' '),\n",
       " ('c', 'e', ':', ' ', 'c'),\n",
       " ('e', ':', ' ', 'c', 'o'),\n",
       " (':', ' ', 'c', 'o', 'n'),\n",
       " (' ', 'c', 'o', 'n', 's'),\n",
       " ('c', 'o', 'n', 's', 't'),\n",
       " ('o', 'n', 's', 't', 'a'),\n",
       " ('n', 's', 't', 'a', 'n'),\n",
       " ('s', 't', 'a', 'n', 't'),\n",
       " ('t', 'a', 'n', 't', 'l'),\n",
       " ('a', 'n', 't', 'l', 'y'),\n",
       " ('n', 't', 'l', 'y', ' '),\n",
       " ('t', 'l', 'y', ' ', 't'),\n",
       " ('l', 'y', ' ', 't', 'h'),\n",
       " ('y', ' ', 't', 'h', 'i'),\n",
       " (' ', 't', 'h', 'i', 'n'),\n",
       " ('t', 'h', 'i', 'n', 'k'),\n",
       " ('h', 'i', 'n', 'k', ' '),\n",
       " ('i', 'n', 'k', ' ', 'a'),\n",
       " ('n', 'k', ' ', 'a', 'b'),\n",
       " ('k', ' ', 'a', 'b', 'o'),\n",
       " (' ', 'a', 'b', 'o', 'u'),\n",
       " ('a', 'b', 'o', 'u', 't'),\n",
       " ('b', 'o', 'u', 't', ' '),\n",
       " ('o', 'u', 't', ' ', 'h'),\n",
       " ('u', 't', ' ', 'h', 'o'),\n",
       " ('t', ' ', 'h', 'o', 'w'),\n",
       " (' ', 'h', 'o', 'w', ' '),\n",
       " ('h', 'o', 'w', ' ', 'y'),\n",
       " ('o', 'w', ' ', 'y', 'o'),\n",
       " ('w', ' ', 'y', 'o', 'u'),\n",
       " (' ', 'y', 'o', 'u', '\\n'),\n",
       " ('y', 'o', 'u', '\\n', 'c'),\n",
       " ('o', 'u', '\\n', 'c', 'o'),\n",
       " ('u', '\\n', 'c', 'o', 'u'),\n",
       " ('\\n', 'c', 'o', 'u', 'l'),\n",
       " ('c', 'o', 'u', 'l', 'd'),\n",
       " ('o', 'u', 'l', 'd', ' '),\n",
       " ('u', 'l', 'd', ' ', 'b'),\n",
       " ('l', 'd', ' ', 'b', 'e'),\n",
       " ('d', ' ', 'b', 'e', ' '),\n",
       " (' ', 'b', 'e', ' ', 'd'),\n",
       " ('b', 'e', ' ', 'd', 'o'),\n",
       " ('e', ' ', 'd', 'o', 'i'),\n",
       " (' ', 'd', 'o', 'i', 'n'),\n",
       " ('d', 'o', 'i', 'n', 'g'),\n",
       " ('o', 'i', 'n', 'g', ' '),\n",
       " ('i', 'n', 'g', ' ', 't'),\n",
       " ('n', 'g', ' ', 't', 'h'),\n",
       " ('g', ' ', 't', 'h', 'i'),\n",
       " (' ', 't', 'h', 'i', 'n'),\n",
       " ('t', 'h', 'i', 'n', 'g'),\n",
       " ('h', 'i', 'n', 'g', 's'),\n",
       " ('i', 'n', 'g', 's', ' '),\n",
       " ('n', 'g', 's', ' ', 'b'),\n",
       " ('g', 's', ' ', 'b', 'e'),\n",
       " ('s', ' ', 'b', 'e', 't'),\n",
       " (' ', 'b', 'e', 't', 't'),\n",
       " ('b', 'e', 't', 't', 'e'),\n",
       " ('e', 't', 't', 'e', 'r'),\n",
       " ('t', 't', 'e', 'r', ' '),\n",
       " ('t', 'e', 'r', ' ', 'a'),\n",
       " ('e', 'r', ' ', 'a', 'n'),\n",
       " ('r', ' ', 'a', 'n', 'd'),\n",
       " (' ', 'a', 'n', 'd', ' '),\n",
       " ('a', 'n', 'd', ' ', 'q'),\n",
       " ('n', 'd', ' ', 'q', 'u'),\n",
       " ('d', ' ', 'q', 'u', 'e'),\n",
       " (' ', 'q', 'u', 'e', 's'),\n",
       " ('q', 'u', 'e', 's', 't'),\n",
       " ('u', 'e', 's', 't', 'i'),\n",
       " ('e', 's', 't', 'i', 'o'),\n",
       " ('s', 't', 'i', 'o', 'n'),\n",
       " ('t', 'i', 'o', 'n', 'i'),\n",
       " ('i', 'o', 'n', 'i', 'n'),\n",
       " ('o', 'n', 'i', 'n', 'g'),\n",
       " ('n', 'i', 'n', 'g', ' '),\n",
       " ('i', 'n', 'g', ' ', 'y'),\n",
       " ('n', 'g', ' ', 'y', 'o'),\n",
       " ('g', ' ', 'y', 'o', 'u'),\n",
       " (' ', 'y', 'o', 'u', 'r'),\n",
       " ('y', 'o', 'u', 'r', 's'),\n",
       " ('o', 'u', 'r', 's', 'e'),\n",
       " ('u', 'r', 's', 'e', 'l'),\n",
       " ('r', 's', 'e', 'l', 'f'),\n",
       " ('s', 'e', 'l', 'f', '\\n')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db30fb8",
   "metadata": {},
   "source": [
    "# Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c88a78f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "288222b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english') # stop words for English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "89cdd8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f8373e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860bee6a",
   "metadata": {},
   "source": [
    "* Stop word for different lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "559a4454",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words2 = stopwords.words('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d9051d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['au',\n",
       " 'aux',\n",
       " 'avec',\n",
       " 'ce',\n",
       " 'ces',\n",
       " 'dans',\n",
       " 'de',\n",
       " 'des',\n",
       " 'du',\n",
       " 'elle',\n",
       " 'en',\n",
       " 'et',\n",
       " 'eux',\n",
       " 'il',\n",
       " 'ils',\n",
       " 'je',\n",
       " 'la',\n",
       " 'le',\n",
       " 'les',\n",
       " 'leur',\n",
       " 'lui',\n",
       " 'ma',\n",
       " 'mais',\n",
       " 'me',\n",
       " 'mme',\n",
       " 'mes',\n",
       " 'moi',\n",
       " 'mon',\n",
       " 'ne',\n",
       " 'nos',\n",
       " 'notre',\n",
       " 'nous',\n",
       " 'on',\n",
       " 'ou',\n",
       " 'par',\n",
       " 'pas',\n",
       " 'pour',\n",
       " 'qu',\n",
       " 'que',\n",
       " 'qui',\n",
       " 'sa',\n",
       " 'se',\n",
       " 'ses',\n",
       " 'son',\n",
       " 'sur',\n",
       " 'ta',\n",
       " 'te',\n",
       " 'tes',\n",
       " 'toi',\n",
       " 'ton',\n",
       " 'tu',\n",
       " 'un',\n",
       " 'une',\n",
       " 'vos',\n",
       " 'votre',\n",
       " 'vous',\n",
       " 'c',\n",
       " 'd',\n",
       " 'j',\n",
       " 'l',\n",
       " '',\n",
       " 'm',\n",
       " 'n',\n",
       " 's',\n",
       " 't',\n",
       " 'y',\n",
       " 't',\n",
       " 'te',\n",
       " 'tes',\n",
       " 'ts',\n",
       " 'tant',\n",
       " 'tante',\n",
       " 'tants',\n",
       " 'tantes',\n",
       " 'suis',\n",
       " 'es',\n",
       " 'est',\n",
       " 'sommes',\n",
       " 'tes',\n",
       " 'sont',\n",
       " 'serai',\n",
       " 'seras',\n",
       " 'sera',\n",
       " 'serons',\n",
       " 'serez',\n",
       " 'seront',\n",
       " 'serais',\n",
       " 'serait',\n",
       " 'serions',\n",
       " 'seriez',\n",
       " 'seraient',\n",
       " 'tais',\n",
       " 'tait',\n",
       " 'tions',\n",
       " 'tiez',\n",
       " 'taient',\n",
       " 'fus',\n",
       " 'fut',\n",
       " 'fmes',\n",
       " 'ftes',\n",
       " 'furent',\n",
       " 'sois',\n",
       " 'soit',\n",
       " 'soyons',\n",
       " 'soyez',\n",
       " 'soient',\n",
       " 'fusse',\n",
       " 'fusses',\n",
       " 'ft',\n",
       " 'fussions',\n",
       " 'fussiez',\n",
       " 'fussent',\n",
       " 'ayant',\n",
       " 'ayante',\n",
       " 'ayantes',\n",
       " 'ayants',\n",
       " 'eu',\n",
       " 'eue',\n",
       " 'eues',\n",
       " 'eus',\n",
       " 'ai',\n",
       " 'as',\n",
       " 'avons',\n",
       " 'avez',\n",
       " 'ont',\n",
       " 'aurai',\n",
       " 'auras',\n",
       " 'aura',\n",
       " 'aurons',\n",
       " 'aurez',\n",
       " 'auront',\n",
       " 'aurais',\n",
       " 'aurait',\n",
       " 'aurions',\n",
       " 'auriez',\n",
       " 'auraient',\n",
       " 'avais',\n",
       " 'avait',\n",
       " 'avions',\n",
       " 'aviez',\n",
       " 'avaient',\n",
       " 'eut',\n",
       " 'emes',\n",
       " 'etes',\n",
       " 'eurent',\n",
       " 'aie',\n",
       " 'aies',\n",
       " 'ait',\n",
       " 'ayons',\n",
       " 'ayez',\n",
       " 'aient',\n",
       " 'eusse',\n",
       " 'eusses',\n",
       " 'et',\n",
       " 'eussions',\n",
       " 'eussiez',\n",
       " 'eussent']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e5b76a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c4f93824",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words3 = stopwords.words('chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "26bc79a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eeb20f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "841"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5705aa",
   "metadata": {},
   "source": [
    "# Remove Stop Word from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f26226a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "846"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swami2='''\n",
    "Born into an aristocratic Bengali Kayastha family of Calcutta,\n",
    "Vivekananda was inclined towards spirituality.\n",
    "\n",
    "He was influenced by his guru, Ramakrishna, from whom he learnt that\n",
    "all living beings were an embodiment of the divine self; therefore,\n",
    "service to God could be rendered by service to humankind.\n",
    "After Ramakrishna's death, Vivekananda toured the Indian subcontinent extensively and\n",
    "acquired first-hand knowledge of the conditions prevailing in British India.\n",
    "\n",
    "He later traveled to the United States, representing India at the 1893\n",
    "Parliament of the World's Religions. Vivekananda conducted hundreds of\n",
    "public and private lectures and classes, disseminating tenets of Hindu\n",
    "philosophy in the United States, England and Europe.\n",
    "\n",
    "In India, Vivekananda is regarded as a patriotic saint, and his birthday is celebrated as National Youth Day'''\n",
    "len(swami2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e019fed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "swami_tokens = word_tokenize(swami2)  # tokenize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a5238e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [w for w in swami_tokens if not w.lower() in stop_words] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8963eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in swami_tokens:\n",
    "    if w not in stop_words: \n",
    "        sent.append(w) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d3595836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Born',\n",
       " 'aristocratic',\n",
       " 'Bengali',\n",
       " 'Kayastha',\n",
       " 'family',\n",
       " 'Calcutta',\n",
       " ',',\n",
       " 'Vivekananda',\n",
       " 'inclined',\n",
       " 'towards',\n",
       " 'spirituality',\n",
       " '.',\n",
       " 'influenced',\n",
       " 'guru',\n",
       " ',',\n",
       " 'Ramakrishna',\n",
       " ',',\n",
       " 'learnt',\n",
       " 'living',\n",
       " 'beings',\n",
       " 'embodiment',\n",
       " 'divine',\n",
       " 'self',\n",
       " ';',\n",
       " 'therefore',\n",
       " ',',\n",
       " 'service',\n",
       " 'God',\n",
       " 'could',\n",
       " 'rendered',\n",
       " 'service',\n",
       " 'humankind',\n",
       " '.',\n",
       " 'Ramakrishna',\n",
       " \"'s\",\n",
       " 'death',\n",
       " ',',\n",
       " 'Vivekananda',\n",
       " 'toured',\n",
       " 'Indian',\n",
       " 'subcontinent',\n",
       " 'extensively',\n",
       " 'acquired',\n",
       " 'first-hand',\n",
       " 'knowledge',\n",
       " 'conditions',\n",
       " 'prevailing',\n",
       " 'British',\n",
       " 'India',\n",
       " '.',\n",
       " 'later',\n",
       " 'traveled',\n",
       " 'United',\n",
       " 'States',\n",
       " ',',\n",
       " 'representing',\n",
       " 'India',\n",
       " '1893',\n",
       " 'Parliament',\n",
       " 'World',\n",
       " \"'s\",\n",
       " 'Religions',\n",
       " '.',\n",
       " 'Vivekananda',\n",
       " 'conducted',\n",
       " 'hundreds',\n",
       " 'public',\n",
       " 'private',\n",
       " 'lectures',\n",
       " 'classes',\n",
       " ',',\n",
       " 'disseminating',\n",
       " 'tenets',\n",
       " 'Hindu',\n",
       " 'philosophy',\n",
       " 'United',\n",
       " 'States',\n",
       " ',',\n",
       " 'England',\n",
       " 'Europe',\n",
       " '.',\n",
       " 'India',\n",
       " ',',\n",
       " 'Vivekananda',\n",
       " 'regarded',\n",
       " 'patriotic',\n",
       " 'saint',\n",
       " ',',\n",
       " 'birthday',\n",
       " 'celebrated',\n",
       " 'National',\n",
       " 'Youth',\n",
       " 'Day',\n",
       " 'Born',\n",
       " 'aristocratic',\n",
       " 'Bengali',\n",
       " 'Kayastha',\n",
       " 'family',\n",
       " 'Calcutta',\n",
       " ',',\n",
       " 'Vivekananda',\n",
       " 'inclined',\n",
       " 'towards',\n",
       " 'spirituality',\n",
       " '.',\n",
       " 'He',\n",
       " 'influenced',\n",
       " 'guru',\n",
       " ',',\n",
       " 'Ramakrishna',\n",
       " ',',\n",
       " 'learnt',\n",
       " 'living',\n",
       " 'beings',\n",
       " 'embodiment',\n",
       " 'divine',\n",
       " 'self',\n",
       " ';',\n",
       " 'therefore',\n",
       " ',',\n",
       " 'service',\n",
       " 'God',\n",
       " 'could',\n",
       " 'rendered',\n",
       " 'service',\n",
       " 'humankind',\n",
       " '.',\n",
       " 'After',\n",
       " 'Ramakrishna',\n",
       " \"'s\",\n",
       " 'death',\n",
       " ',',\n",
       " 'Vivekananda',\n",
       " 'toured',\n",
       " 'Indian',\n",
       " 'subcontinent',\n",
       " 'extensively',\n",
       " 'acquired',\n",
       " 'first-hand',\n",
       " 'knowledge',\n",
       " 'conditions',\n",
       " 'prevailing',\n",
       " 'British',\n",
       " 'India',\n",
       " '.',\n",
       " 'He',\n",
       " 'later',\n",
       " 'traveled',\n",
       " 'United',\n",
       " 'States',\n",
       " ',',\n",
       " 'representing',\n",
       " 'India',\n",
       " '1893',\n",
       " 'Parliament',\n",
       " 'World',\n",
       " \"'s\",\n",
       " 'Religions',\n",
       " '.',\n",
       " 'Vivekananda',\n",
       " 'conducted',\n",
       " 'hundreds',\n",
       " 'public',\n",
       " 'private',\n",
       " 'lectures',\n",
       " 'classes',\n",
       " ',',\n",
       " 'disseminating',\n",
       " 'tenets',\n",
       " 'Hindu',\n",
       " 'philosophy',\n",
       " 'United',\n",
       " 'States',\n",
       " ',',\n",
       " 'England',\n",
       " 'Europe',\n",
       " '.',\n",
       " 'In',\n",
       " 'India',\n",
       " ',',\n",
       " 'Vivekananda',\n",
       " 'regarded',\n",
       " 'patriotic',\n",
       " 'saint',\n",
       " ',',\n",
       " 'birthday',\n",
       " 'celebrated',\n",
       " 'National',\n",
       " 'Youth',\n",
       " 'Day',\n",
       " 'Born',\n",
       " 'aristocratic',\n",
       " 'Bengali',\n",
       " 'Kayastha',\n",
       " 'family',\n",
       " 'Calcutta',\n",
       " ',',\n",
       " 'Vivekananda',\n",
       " 'inclined',\n",
       " 'towards',\n",
       " 'spirituality',\n",
       " '.',\n",
       " 'He',\n",
       " 'influenced',\n",
       " 'guru',\n",
       " ',',\n",
       " 'Ramakrishna',\n",
       " ',',\n",
       " 'learnt',\n",
       " 'living',\n",
       " 'beings',\n",
       " 'embodiment',\n",
       " 'divine',\n",
       " 'self',\n",
       " ';',\n",
       " 'therefore',\n",
       " ',',\n",
       " 'service',\n",
       " 'God',\n",
       " 'could',\n",
       " 'rendered',\n",
       " 'service',\n",
       " 'humankind',\n",
       " '.',\n",
       " 'After',\n",
       " 'Ramakrishna',\n",
       " \"'s\",\n",
       " 'death',\n",
       " ',',\n",
       " 'Vivekananda',\n",
       " 'toured',\n",
       " 'Indian',\n",
       " 'subcontinent',\n",
       " 'extensively',\n",
       " 'acquired',\n",
       " 'first-hand',\n",
       " 'knowledge',\n",
       " 'conditions',\n",
       " 'prevailing',\n",
       " 'British',\n",
       " 'India',\n",
       " '.',\n",
       " 'He',\n",
       " 'later',\n",
       " 'traveled',\n",
       " 'United',\n",
       " 'States',\n",
       " ',',\n",
       " 'representing',\n",
       " 'India',\n",
       " '1893',\n",
       " 'Parliament',\n",
       " 'World',\n",
       " \"'s\",\n",
       " 'Religions',\n",
       " '.',\n",
       " 'Vivekananda',\n",
       " 'conducted',\n",
       " 'hundreds',\n",
       " 'public',\n",
       " 'private',\n",
       " 'lectures',\n",
       " 'classes',\n",
       " ',',\n",
       " 'disseminating',\n",
       " 'tenets',\n",
       " 'Hindu',\n",
       " 'philosophy',\n",
       " 'United',\n",
       " 'States',\n",
       " ',',\n",
       " 'England',\n",
       " 'Europe',\n",
       " '.',\n",
       " 'In',\n",
       " 'India',\n",
       " ',',\n",
       " 'Vivekananda',\n",
       " 'regarded',\n",
       " 'patriotic',\n",
       " 'saint',\n",
       " ',',\n",
       " 'birthday',\n",
       " 'celebrated',\n",
       " 'National',\n",
       " 'Youth',\n",
       " 'Day']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "396cdf99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9d298d",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "* Normalize words into its base form is called stemming.\n",
    "\n",
    "There are three type of stemmer--\n",
    "1) Porter\n",
    "2) lancaster \n",
    "3) snowball"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313bdf35",
   "metadata": {},
   "source": [
    "# Porter Stemmer code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a3d5996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a000e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d19e67cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem(\"having\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2136645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_stem=[\"python\",\"pythoner\",\"pythoning\",\"pythoned\",'pythonly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f4901ad6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: python\n",
      "pythoner: python\n",
      "pythoning: python\n",
      "pythoned: python\n",
      "pythonly: pythonli\n"
     ]
    }
   ],
   "source": [
    "for words in words_to_stem:\n",
    "    print(words+\": \"+pst.stem(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f4269e",
   "metadata": {},
   "source": [
    "# Lancaster Stemmer code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4cfcc510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "47cc9267",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fbcb23d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hav'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst.stem(\"having\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6f0ff79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: python\n",
      "pythoner: python\n",
      "pythoning: python\n",
      "pythoned: python\n",
      "pythonly: python\n"
     ]
    }
   ],
   "source": [
    "for words in words_to_stem:\n",
    "    print(words+\": \"+lst.stem(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48773a3",
   "metadata": {},
   "source": [
    "# Snowball Stemmer code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ff594c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fb462bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "st=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "49147406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.stem(\"having\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cb502560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: python\n",
      "pythoner: python\n",
      "pythoning: python\n",
      "pythoned: python\n",
      "pythonly: python\n"
     ]
    }
   ],
   "source": [
    "for words in words_to_stem:\n",
    "    print(words+\": \"+st.stem(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94d50af",
   "metadata": {},
   "source": [
    "# Similaritys   \n",
    "* 1) Cosine Similarity.\n",
    "             cos(x,y) =       x.y\n",
    "                        ----------------\n",
    "                         ||x|| * ||y||\n",
    "            ||x|| = (x1)^2 + (x2)^2 + (x3)^2+........+(Xn)^2\n",
    "            ||y|| = (y1)^2 + (y2)^2 + (y3)^2+........+(Yn)^2\n",
    "            x.y = (x1*y1) + (x2*y2) + (x3*y3) +..........(xn*yn).\n",
    "                         \n",
    "* 2) Jaccard Similarity.\n",
    "             A intersection B\n",
    "           --------------------\n",
    "                A Union B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a05f574",
   "metadata": {},
   "source": [
    "# Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e78daa96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [3,2,0,5]\n",
    "y = [1,0,0,0]\n",
    "\n",
    "n = len(x)\n",
    "i = 0\n",
    "xy = 0\n",
    "while(n > 0):\n",
    "    xy += (x[i]*y[i])\n",
    "    i=i+1\n",
    "    n = n - 1\n",
    "xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d0d6383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.164414002968976"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 0\n",
    "n = len(x)\n",
    "i = 0\n",
    "while(n > 0):\n",
    "    w += (x[i]**2)\n",
    "    i=i+1\n",
    "    n = n - 1\n",
    "mx = w ** (0.5)\n",
    "mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05641b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 0\n",
    "n = len(y)\n",
    "i = 0\n",
    "while(n > 0):\n",
    "    w += (y[i]**2)\n",
    "    i=i+1\n",
    "    n = n - 1\n",
    "my = w ** (0.5)\n",
    "my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7311fd8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48666426339228763"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = my * mx\n",
    "cossim = xy/d\n",
    "cossim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986d2eeb",
   "metadata": {},
   "source": [
    "# Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b6d3c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0,1,2,5,6]\n",
    "y = [0,2,3,5,7,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a26b29e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sx = set(x)\n",
    "sy = set(y)\n",
    "\n",
    "un = sx.union(sy)\n",
    "itn = sx.intersection(sy)\n",
    "\n",
    "unn = len(un)\n",
    "inn = len(itn)\n",
    "\n",
    "js = inn/unn\n",
    "\n",
    "js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793cd4c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
